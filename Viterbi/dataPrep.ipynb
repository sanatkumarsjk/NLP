{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from itertools import permutations \n",
    "from itertools import combinations_with_replacement \n",
    "\n",
    "vocab = set()\n",
    "\n",
    "def readFile(filename):\n",
    "    f=open(filename, \"r\")\n",
    "    if f.mode == 'r':\n",
    "        contents =f.read()\n",
    "    return contents\n",
    "\n",
    "def writeFile(filename, data):\n",
    "    file1 = open(filename,\"w+\")\n",
    "    file1.writelines(data) \n",
    "    file1.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateFreq(data):\n",
    "    print(\"Preprocessing data\")\n",
    "    data=\"ST/S \"+ data\n",
    "    data = data.replace('\\n',\" EN/E ST/S \")[:-5]\n",
    "    ogData = data\n",
    "    #deleting the tags\n",
    "    tags = ['/A','/C','/D','/M','/N','/O','/P','/R','/V','/W','/E','/S']\n",
    "    for i in tags:\n",
    "        data = data.replace(i,'')\n",
    "   \n",
    "    #claculating frequency    \n",
    "    freq = Counter(data.split(' '))\n",
    "    \n",
    "    #generating final string\n",
    "    unknownSet = set()\n",
    "    for key,values in freq.items():\n",
    "        if values < 2:\n",
    "            unknownSet.add(key)\n",
    "        else: vocab.add(key)\n",
    "    \n",
    "    result = ''    \n",
    "    for i in ogData.split():   \n",
    "        words = i.split('/')\n",
    "        if words[0] in unknownSet or words[0] not in vocab:\n",
    "            result+='UNK/'+words[1]+' '\n",
    "        else: result += words[0]+\"/\"+words[1]+' '\n",
    "    return result\n",
    "\n",
    "\n",
    "def transProba(data, alpha):\n",
    "    print(\"Calculating transitional probabilities\")\n",
    "    tags = ['A', 'C', 'D', 'M', 'N', 'O', 'P', 'R', 'V', 'W', 'E', 'S']\n",
    "    perm = permutations(tags,2) \n",
    "    comb = combinations_with_replacement(tags,2) \n",
    "    dictComb = {}\n",
    "    dict = {}\n",
    "    \n",
    "    #Generating dictionaries\n",
    "    for i in perm:\n",
    "        if i[0] != 'S' and i[1] != 'E':\n",
    "            dictComb[i] = 0\n",
    "    for i in comb:\n",
    "        if i[0] != 'S' and i[1] != 'E':\n",
    "            dictComb[i] = 0\n",
    "    for i in tags:\n",
    "        dict[i] = 0\n",
    "    dict['S'] = 1 \n",
    "    data = data.split()\n",
    "    i=1\n",
    "    \n",
    "    #generating counts for (y,y') and (y')\n",
    "    while i < len(data):\n",
    "        try:\n",
    "            words = data[i].split('/')\n",
    "            prevWords = data[i-1].split('/')\n",
    "            if words[1] != 'S':\n",
    "                dictComb[(words[1], prevWords[1])]+=1\n",
    "            dict[words[1]]+=1\n",
    "            i+=1\n",
    "        except:\n",
    "            dict[words[1]]+=1\n",
    "            i+=1\n",
    "            \n",
    "    #calculating transitional probabilities\n",
    "    result = {}\n",
    "    for key in dictComb:\n",
    "        try:\n",
    "            result[key] = (dictComb[key]+alpha) / (dict[key[1]]+(alpha*(len(tags)+1-2)))\n",
    "        except:\n",
    "             result[key] = 0         \n",
    "    return result \n",
    "\n",
    "def emmiProba(data,beta):\n",
    "    print(\"Calculating emmision probabilities\")\n",
    "    dictComb = {}\n",
    "    dict = {}\n",
    "    for i in data.split():\n",
    "        word = i.split('/')\n",
    "        \n",
    "        key = (word[0],word[1])\n",
    "        \n",
    "        if key in dictComb: dictComb[key]+=1\n",
    "        else: dictComb[key] = 1\n",
    "            \n",
    "        if word[1] in dict: dict[word[1]]+=1\n",
    "        else: dict[word[1]] = 1\n",
    "    \n",
    "    for key in dictComb:\n",
    "        try:\n",
    "            dictComb[key] = (dictComb[key]+beta) / (dict[key[1]]+(beta*(len(vocab))))\n",
    "        except:\n",
    "            dictComb[key] = 0\n",
    "    return dictComb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data\n",
      "Calculating transitional probabilities\n",
      "Calculating emmision probabilities\n"
     ]
    }
   ],
   "source": [
    "# test = \"In/C of/C aftermath/N of/C the/D stock/N market/N 's/P gut-wrenching/A 190-point/A drop/N on/C Oct./N 13/O ,/O Kidder/N ,/O Peabody/N &/C Co./N 's/P 1,400/O stockbrokers/N across/C the/D country/N began/V a/D telephone/N\\n\"\n",
    "# writeFile(\"data/processedTrn.txt\", calculateFreq(data)[:-5])\n",
    "\n",
    "xdata = readFile(\"data/trn.pos\")\n",
    "data =  calculateFreq(data)\n",
    "tp = transProba(data,1)\n",
    "ep = emmiProba(data,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(transProb, emissionProb, sentence, tags):\n",
    "    dp = [[[1,None] if i == 0 else [0, None] for i in range(len(sentence.split()))] for _ in range(len(tags))]\n",
    "    words = sentence.split()\n",
    "    \n",
    "    for word in range(1,len(dp[0])):\n",
    "        if word == 1:\n",
    "            tag_seq = ['S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S', 'S']\n",
    "        else: tag_seq = tags\n",
    "        for tag in range(len(dp)):\n",
    "            temp_score = 0\n",
    "            back_item = None\n",
    "            for item in range(len(dp)):              \n",
    "                try:\n",
    "                    tran = transProb[(tags[tag], tag_seq[item])]\n",
    "                    emis =  emissionProb[(words[word].split('/')[0], tags[tag])]                     \n",
    "                    score = tran * emis * dp[item][word-1][0]\n",
    "                except:\n",
    "                    score = 0\n",
    "                if temp_score < score:\n",
    "                    back_item = item\n",
    "                temp_score = max(temp_score, score)\n",
    "            dp[tag][word][0] = temp_score\n",
    "            dp[tag][word][1] = back_item\n",
    "    return dp\n",
    "\n",
    "def backtrack(dp,tags):\n",
    "    mx = 0\n",
    "    mx_id = 0\n",
    "    seq = [None]\n",
    "    for i in range(len(dp)):\n",
    "        if mx < dp[i][-2][0]:\n",
    "            mx = dp[i][-2][0]\n",
    "            mx_id = dp[i][-2][1]\n",
    "            seq[0] = i\n",
    "            \n",
    "    seq.append(mx_id)        \n",
    "    ptr = mx_id        \n",
    "    for i in range(len(dp[0])-3, 0, -1):\n",
    "#         print(ptr,i, dp[ptr][i])\n",
    "        ptr = dp[ptr][i][1]\n",
    "        seq.append(ptr)\n",
    "    pos = []\n",
    "    for i in seq:\n",
    "        pos.append(tags[i])\n",
    "    return pos[-1::-1]\n",
    "tags = ['A', 'C', 'D', 'M', 'N', 'O', 'P', 'R', 'V', 'W']\n",
    "\n",
    "\n",
    "def processTest(data):\n",
    "    print(\"Preprocessing data\")\n",
    "    data=\"ST/S \"+ data\n",
    "    data = data.replace('\\n',\" EN/E ST/S \")[:-5]\n",
    "    ogData = data\n",
    "    \n",
    "    #deleting the tags\n",
    "    tags = ['/A','/C','/D','/M','/N','/O','/P','/R','/V','/W','/E','/S']\n",
    "    for i in tags:\n",
    "        data = data.replace(i,'')\n",
    "        \n",
    "    #generating final string    \n",
    "    result = ''    \n",
    "    for i in ogData.split():   \n",
    "        words = i.split('/')\n",
    "        if words[0] not in vocab:\n",
    "            result+='UNK/'+words[1]+' '\n",
    "        else: result += words[0]+\"/\"+words[1]+' '\n",
    "    return result\n",
    "\n",
    "def extractTags(data):\n",
    "    result = []\n",
    "    for i in data.split():   \n",
    "        words = i.split('/')\n",
    "        result.append(words[1])\n",
    "    return result\n",
    "\n",
    "def calacc(gt,pred):\n",
    "    correct = 0\n",
    "    for i,j in zip(gt,pred):\n",
    "        if i==j:\n",
    "            correct+=1\n",
    "    return correct,len(gt)\n",
    "\n",
    "def pipeline(test_data):\n",
    "    dp = []\n",
    "    acc = []\n",
    "    for i in test_data.split('/E'):\n",
    "        try:\n",
    "            sample = i + '/E'\n",
    "            gt = extractTags(sample)\n",
    "            dp = viterbi(tp, ep, sample, tags)\n",
    "            ta = backtrack(dp,tags)\n",
    "            acc.append(calacc(gt[1:-1], ta[1:]))\n",
    "        except:\n",
    "            print('')\n",
    "    return acc, dp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert the estimated probabilities from the previous step into log space and im-plement the Viterbi decoding algorithm as in Algorithm 11in [Eisenstein, 2018].  Report theaccuracy of your decoder on the dev setdev.pos\n",
    "## Best accuracy is 0.9566347008709313 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data\n",
      "\n",
      "\n",
      "\n",
      "Accuracy is:  0.9566347008709313\n"
     ]
    }
   ],
   "source": [
    "dev = readFile(\"data/dev.pos\")\n",
    "dev_data = processTest(dev)\n",
    "dev_acc, tst_dp = pipeline(dev_data)\n",
    "correct, total = 0, 0\n",
    "for i in dev_acc:\n",
    "    total+=i[1]\n",
    "    correct+=i[0]\n",
    "print(\"Accuracy is: \",correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Run the model selected from the previous step on the test settst.pos, and reportthe accuracy\n",
    "## Best accuracy is 0.9590364050774317"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data\n",
      "\n",
      "\n",
      "Accuracy is:  0.9590364050774317\n"
     ]
    }
   ],
   "source": [
    "test = readFile(\"data/tst.pos\")\n",
    "test_data = processTest(test)\n",
    "tst_acc, tst_dp = pipeline(test_data)\n",
    "\n",
    "correct, total = 0, 0\n",
    "for i in tst_acc:\n",
    "    total+=i[1]\n",
    "    correct+=i[0]\n",
    "\n",
    "print(\"Accuracy is: \",correct/total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tune α and β to find the best accuracy on the dev set.  Report the best accuracynumber and the values of α and β.\n",
    "## Best value for α and β are 1 and 1 respectively; giving accuracy of: 0.95 on both dev and tst set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
