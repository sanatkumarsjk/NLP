{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Package Dependency\n",
    "\n",
    "- [nltk](https://www.nltk.org)\n",
    "- [sklearn](http://scikit-learn.org/stable/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data ...\n",
      "40000, 40000\n",
      "Development data ...\n",
      "5000, 5000\n"
     ]
    }
   ],
   "source": [
    "# Load packages\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "import numpy as np\n",
    "# Load data\n",
    "trn_texts = open(\"trn-reviews.txt\").read().strip().split(\"\\n\")\n",
    "trn_labels = open(\"trn-labels.txt\").read().strip().split(\"\\n\")\n",
    "print(\"Training data ...\")\n",
    "print(\"%d, %d\" % (len(trn_texts), len(trn_labels)))\n",
    "\n",
    "dev_texts = open(\"dev-reviews.txt\").read().strip().split(\"\\n\")\n",
    "dev_labels = open(\"dev-labels.txt\").read().strip().split(\"\\n\")\n",
    "print(\"Development data ...\")\n",
    "print(\"%d, %d\" % (len(dev_texts), len(dev_labels)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "50000\n",
      "100000\n",
      "150000\n",
      "200000\n",
      "250000\n",
      "300000\n",
      "350000\n"
     ]
    }
   ],
   "source": [
    "glove = pd.read_csv(\"glove.6b.50d.txt\", sep=' ', header=None, quotechar=None,  quoting=3)\n",
    "dict = {}\n",
    "for i, row in glove.iterrows():\n",
    "    if len(dict)%50000 ==0:\n",
    "        print(len(dict))\n",
    "    dict[row[0]] = np.array(row.drop([0]))\n",
    "    \n",
    "    \n",
    "wtrn_data = np.array([WordPunctTokenizer().tokenize(i.lower()) for i in trn_texts])\n",
    "wdev_data = np.array([WordPunctTokenizer().tokenize(i.lower()) for i in dev_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "0\n",
      "this block is done\n"
     ]
    }
   ],
   "source": [
    "def txt_rep(data):\n",
    "    new_data = np.array([[0]*50])\n",
    "    k = 0\n",
    "    for i in data:\n",
    "        addition = np.array([0]*50)\n",
    "        count = 0\n",
    "        for j in i:\n",
    "            try:\n",
    "                temp = dict[j]\n",
    "                addition = np.sum([temp, addition], axis=0)\n",
    "                count+=1\n",
    "            except: pass\n",
    "        count = max(1, count)\n",
    "        try:\n",
    "            new_data = np.append(new_data,[addition/count], axis=0)\n",
    "        except:\n",
    "            print(addition, count)\n",
    "        if k%10000 == 0:\n",
    "            print(k)\n",
    "        k+=1\n",
    "    return new_data\n",
    "\n",
    "gtrn_data = txt_rep(wtrn_data)[1:]\n",
    "gdev_data = txt_rep(wdev_data)[1:]\n",
    "print('this block is done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 50)\n"
     ]
    }
   ],
   "source": [
    "print(gtrn_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 50)\n",
      "Training accuracy = 0.516325\n",
      "Dev accuracy = %f 0.5464\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "print(gtrn_data.shape)\n",
    "# Define a LR classifier\n",
    "classifier = LogisticRegression(solver=\"liblinear\", multi_class=\"auto\")\n",
    "classifier.fit(gtrn_data, trn_labels)\n",
    "\n",
    "# Measure the performance on training and dev data\n",
    "print(\"Training accuracy = %f\" % classifier.score(gtrn_data, trn_labels))\n",
    "print(\"Dev accuracy = %f\", classifier.score(gdev_data, dev_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing without any feature selection\n",
      "(40000, 77166)\n",
      "(5000, 77166)\n"
     ]
    }
   ],
   "source": [
    "choice = 1\n",
    "\n",
    "if choice == 1:\n",
    "    print(\"Preprocessing without any feature selection\")\n",
    "    vectorizer = CountVectorizer(lowercase=False)\n",
    "    # vocab size 77166\n",
    "elif choice == 2:\n",
    "    print(\"Lowercasing all the tokens\")\n",
    "    vectorizer = CountVectorizer(lowercase=True)\n",
    "    # vocab size 60610\n",
    "else:\n",
    "    raise ValueError(\"Unrecognized value: choice = %d\" % choice)\n",
    "\n",
    "trn_data = vectorizer.fit_transform(trn_texts)\n",
    "print(trn_data.shape)\n",
    "dev_data = vectorizer.transform(dev_texts)\n",
    "print(dev_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 77166) (40000, 50)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import coo_matrix, hstack, csr_matrix\n",
    "\n",
    "# dev_data = dev_data.toarray()\n",
    "print(trn_data.shape, gtrn_data.shape)\n",
    "# cdev_data = np.concatenate((dev_data.toarray(),gdev_data), axis=1)\n",
    "# ctrn_data = np.concatenate((trn_data.toarray(),gtrn_data), axis=1)\n",
    "\n",
    "A = csr_matrix(gtrn_data.astype(float))\n",
    "ctrn_data = hstack([trn_data,A])\n",
    "B = csr_matrix(gdev_data.astype(float))\n",
    "cdev_data = hstack([dev_data,B])\n",
    "\n",
    "# def comb(data, gdata):\n",
    "#     new_data = np.array([[0]*77216])\n",
    "#     k = 0\n",
    "#     for i,j in zip(data,gdata):\n",
    "#         if k%(n/10) ==0:\n",
    "#             print (k)\n",
    "#         if k == n:\n",
    "#             print(k)\n",
    "#             break\n",
    "#         new_data = np.append(new_data, [np.append(i.toarray(), j )], axis=0)   \n",
    "#         k+=1\n",
    "#     return new_data\n",
    "# ctrn_data = comb(trn_data, gtrn_data)[1:]    \n",
    "# cdev_data = comb(dev_data, gdev_data)[1:]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 77216)\n"
     ]
    }
   ],
   "source": [
    "print(ctrn_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Logistic Regression\n",
    "\n",
    "Please refer to the document of [_LogisticRegression_](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) for the parameters of this function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.941400\n",
      "Dev accuracy = %f 0.6134\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# Define a LR classifier\n",
    "classifier = LogisticRegression(solver=\"liblinear\", multi_class=\"auto\")\n",
    "classifier.fit(ctrn_data, trn_labels)\n",
    "\n",
    "# Measure the performance on training and dev data\n",
    "print(\"Training accuracy = %f\" % classifier.score(ctrn_data, trn_labels))\n",
    "print(\"Dev accuracy = %f\", classifier.score(cdev_data, dev_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ssjk\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\sag.py:334: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.751075\n",
      "Dev accuracy = %f 0.6394\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# Define a LR classifier\n",
    "classifier = LogisticRegression(solver=\"saga\", multi_class=\"auto\")\n",
    "classifier.fit(ctrn_data, trn_labels)\n",
    "\n",
    "# Measure the performance on training and dev data\n",
    "print(\"Training accuracy = %f\" % classifier.score(ctrn_data, trn_labels))\n",
    "print(\"Dev accuracy = %f\", classifier.score(cdev_data, dev_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.792175\n",
      "Dev accuracy = %f 0.6362\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# Define a LR classifier\n",
    "classifier = LogisticRegression(solver=\"sag\", multi_class=\"auto\")\n",
    "classifier.fit(ctrn_data, trn_labels)\n",
    "\n",
    "# Measure the performance on training and dev data\n",
    "print(\"Training accuracy = %f\" % classifier.score(ctrn_data, trn_labels))\n",
    "print(\"Dev accuracy = %f\", classifier.score(cdev_data, dev_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ssjk\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy = 0.741375\n",
      "Dev accuracy = %f 0.6272\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define a LR classifier\n",
    "classifier = LogisticRegression(solver=\"lbfgs\", multi_class=\"auto\")\n",
    "classifier.fit(ctrn_data, trn_labels)\n",
    "\n",
    "# Measure the performance on training and dev data\n",
    "print(\"Training accuracy = %f\" % classifier.score(ctrn_data, trn_labels))\n",
    "print(\"Dev accuracy = %f\", classifier.score(cdev_data, dev_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
